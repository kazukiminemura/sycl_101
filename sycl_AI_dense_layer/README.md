# サンプルコード：SYCLを使った簡単なAI推論（1層のDense Layer）
シンプルなニューラルネットワークの推論部分をSYCLで実装する例を示します。この例では、SYCLの行列演算を使って、簡単な1層のニューラルネットワーク（Dense Layer）で推論を行います。

## 概要
入力データと重み行列を使って、1層のDense Layer（全結合層）の推論を行います。SYCLのparallel_forを使って並列計算を実装しています。

## コードの説明
### ネットワークの構造: 
この例では、1層の全結合層（Dense Layer）を実装しています。入力は4次元のベクトルで、1Mつの出力ニューロンがあります。各ニューロンには重みベクトルとバイアスがあります。    

```
   Input        Weights      Bias         Output
  -------      ---------    -------      ---------
   [X0] -------- W0,0 -----> [O0] --+--> Output 0
   [X1] -------- W0,1 -----> [O0] --|   
   [X2] -------- W0,2 -----> [O0] --|   
   [X3] -------- W0,3 -----> [O0] --|   
                                +--- Bias 0

   [X0] -------- W1,0 -----> [O1] --+--> Output 1
   [X1] -------- W1,1 -----> [O1] --|   
   [X2] -------- W1,2 -----> [O1] --|   
   [X3] -------- W1,3 -----> [O1] --|   
                                +--- Bias 1

   [X0] -------- W2,0 -----> [O2] --+--> Output 2
   [X1] -------- W2,1 -----> [O2] --|   
   [X2] -------- W2,2 -----> [O2] --|   
   [X3] -------- W2,3 -----> [O2] --|   
                                +--- Bias 2
```
説明：  
X0, X1, X2, X3 は入力ベクトルの成分です。   
W0,0, W0,1, W1,0 などは、各ニューロンに対応する重みです。   
各ニューロンの計算にはバイアスが加えられ、最終的に出力が生成されます。  

### データの定義:   
input_data：入力データ（4次元ベクトル）。   
weights_data：3つのニューロンに対する重み行列。各ニューロンの重みベクトルは1M次元です。  
bias_data：各ニューロンに対するバイアス。   
### SYCLカーネルの実行: 
parallel_forを使用して、各ニューロンの出力を並列に計算しています。各ニューロンは、入力ベクトルとその重みベクトルの内積を計算し、バイアスを加算します。      
### メモリ管理: 
SYCLのUSM（Unified Shared Memory）を使って、ホストとデバイスが共有するメモリを確保しています。malloc_sharedを使って、ホストとデバイスの両方からアクセス可能なメモリ領域を確保し、freeで解放します。 
### 出力の表示: 
カーネルの実行結果として計算された出力を表示しています。
```
$ ./sycl_dense_layer
Running on NVIDIA GeForce RTX 3060 Ti
Average execution time (original) over 10000 iterations: 1072.96 microseconds

$ ./sycl_dense_layer_optimized 
Running on NVIDIA GeForce RTX 3060 Ti
Average execution time (optimized) over 10000 iterations: 890.514 microseconds
```



# SYCLカーネルの最適化を行います。
### ループのアンロール (Loop Unrolling):
SYCLカーネルの内側のループをアンロールして、実行効率を高めることが可能です。これにより、パイプライン化が効率化され、オーバーヘッドが削減されます。      
### データアクセスの最適化:
メモリアクセスがボトルネックになることが多いため、キャッシュ効率を向上させるための工夫が必要です。特に、input と weights のアクセスはストライドが広がりやすいため、データアクセスを最適化します。  
### 並列度の向上:
SYCLのサブグループやワークグループを有効に活用して、より高い並列性を確保します。  

## 最適化のポイント
ワークグループのサイズ指定:   
nd_range<1>(range<1>(output_size), range<1>(64)) で、ワークグループのサイズを64に設定しました。これにより、GPUやCPU上で高い並列性を得られます。 
## ループのアンロール:  
#pragma unroll 4 により、ループのアンロールを試みています。これにより、ループのオーバーヘッドを減らし、パイプライン化が促進されます。  
## 境界条件のチェック:  
if (i < output_size) で、カーネルが無駄に計算されないように範囲外アクセスを防止しています。  
## SYCLの効率化のためのnd_item:  
nd_item は、グローバルおよびローカルIDを使って並列計算を効率化します。    